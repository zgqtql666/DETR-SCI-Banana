# YOLOv8-MobileViT-xs summary: 420 layers, 2438928 parameters, 2438912 gradients, 14.2 GFLOPs
# YOLOv8-MobileViT-xs summary: 420 layers, 2438928 parameters, 2438912 gradients, 14.2 GFLOPs
# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect

# Parameters
nc: 80  # number of classes
kpt_shape: [17, 3]  # number of keypoints, number of dims (2 for x,y or 3 for x,y,visible)
scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [16, 3, 2]]  # 0-P1/2
  - [-1, 1, MV2Block, [32, 1, 4]]  # 1
  - [-1, 1, MV2Block, [48, 2, 4]]  # 2-p2
  - [-1, 1, MV2Block, [48, 1, 4]]  # 3
  - [-1, 1, MV2Block, [48, 1, 4]]  # 4
  - [-1, 1, MV2Block, [64, 2, 4]]  # 5-P3
  - [-1, 1, MobileViTBlock, [96, 2, 3, 2, 192, 0]] # out 6
  - [-1, 1, MV2Block, [80, 2, 4]]  # 7-P4
  - [-1, 1, MobileViTBlock, [120, 4, 3 ,2, 240, 0]] # out 8
  - [-1, 1, MV2Block, [96, 2, 4]]  # 9-p5
  - [-1, 1, MobileViTBlock, [144, 3, 3, 1, 288, 0]] # out 10


# YOLOv8.0n head
head:
  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 8], 1, Concat, [1]]  # cat backbone P4
  - [-1, 1, C2f, [72]]  # 13

  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 6], 1, Concat, [1]]  # cat backbone P3
  - [-1, 1, C2f, [36]]  # 16 (P3/8-small)

  - [-1, 1, Conv, [36, 3, 2]]
  - [[-1, 13], 1, Concat, [1]]  # cat head P4
  - [-1, 1, C2f, [72]]  # 19 (P4/16-medium)

  - [-1, 1, Conv, [72, 3, 2]]
  - [[-1, 10], 1, Concat, [1]]  # cat head P5
  - [-1, 1, C2f, [144]]  # 22 (P5/32-large)

  - [[16, 19, 22], 1, Pose, [nc, kpt_shape]]  # Detect(P3, P4, P5)

