# YOLOv8-MobileViT-xxs summary: 420 layers, 1444528 parameters, 1444512 gradients, 6.6 GFLOPs
# YOLOv8-MobileViT-xxs summary: 420 layers, 1444528 parameters, 1444512 gradients, 6.6 GFLOPs
# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect

# Parameters
nc: 80  # number of classes
kpt_shape: [17, 3]  # number of keypoints, number of dims (2 for x,y or 3 for x,y,visible)
scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [16, 3, 2]]  # 0-P1/2
  - [-1, 1, MV2Block, [16, 1, 2]]  # 1
  - [-1, 1, MV2Block, [24, 2, 2]]  # 2-p2
  - [-1, 1, MV2Block, [24, 1, 2]]  # 3
  - [-1, 1, MV2Block, [24, 1, 2]]  # 4
  - [-1, 1, MV2Block, [48, 2, 2]]  # 5-P3
  - [-1, 1, MobileViTBlock, [64, 2, 3, 2, 128, 0]] 
  - [-1, 1, MV2Block, [64, 2, 2]]  # 7-P4
  - [-1, 1, MobileViTBlock, [80, 4, 3 ,2, 160, 0]] 
  - [-1, 1, MV2Block, [80, 2, 2]]  # 9-p5
  - [-1, 1, MobileViTBlock, [96, 3, 3, 1, 192, 0]] 

# YOLOv8.0n head
head:
  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 8], 1, Concat, [1]]  # cat backbone P4
  - [-1, 1, C2f, [48]]  # 13

  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 6], 1, Concat, [1]]  # cat backbone P3
  - [-1, 1, C2f, [24]]  # 16 (P3/8-small)

  - [-1, 1, Conv, [24, 3, 2]]
  - [[-1, 13], 1, Concat, [1]]  # cat head P4
  - [-1, 1, C2f, [48]]  # 19 (P4/16-medium)

  - [-1, 1, Conv, [48, 3, 2]]
  - [[-1, 10], 1, Concat, [1]]  # cat head P5
  - [-1, 1, C2f, [96]]  # 22 (P5/32-large)

  - [[16, 19, 22], 1, Pose, [nc, kpt_shape]]  # Detect(P3, P4, P5)

